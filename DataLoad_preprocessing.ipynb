{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "url retreiver\n",
    "\"\"\"\n",
    "def download(url, savepath='./'):\n",
    "    def reporthook(a, b, c):\n",
    "        print(\"\\rdownloading: %5.1f%%\" % (a * b * 100.0 / c), end=\"\")\n",
    "    filename = os.path.basename(url)\n",
    "    # 判断文件是否存在，如果不存在则下载\n",
    "    if not os.path.isfile(os.path.join(savepath, filename)):\n",
    "        print('Downloading data from %s' % url)\n",
    "        urlretrieve(url, os.path.join(savepath, filename), reporthook=reporthook)\n",
    "        print('\\nDownload finished!')\n",
    "    else:\n",
    "        print('File already exsits!')\n",
    "    # 获取文件大小\n",
    "    filesize = os.path.getsize(os.path.join(savepath, filename))\n",
    "    # 文件大小默认以Bytes计， 转换为Mb\n",
    "    print('File size = %.2f Mb' % (filesize/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = './training-zombie.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./training')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf readfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = example['image']\n",
    "    class_label = example['class']\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    class_label = tf.cast(class_label, tf.int32)\n",
    "    return image, class_label\n",
    "\n",
    "def load_dataset(filenames):\n",
    "  # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n",
    "  # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n",
    "  # to allow order-altering optimizations.\n",
    "\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO) # faster\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_batched_dataset(filenames):\n",
    "    dataset = load_dataset(filenames)\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False) # drop_remainder will be needed on TPU\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = get_batched_dataset(training_filenames)\n",
    "    dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset():\n",
    "    dataset = get_batched_dataset(validation_filenames)\n",
    "    dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.tensorflow.org/guide/data_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "注意 \n",
    "    tf.data.Dataset.from_tensor_slices 所有input shape 必須要相符\n",
    "\"\"\"\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df.values(nparray), target.values(nparray)))\n",
    "\n",
    "tf.data.Dataset.list_files(\"/path/*.txt\")\n",
    "\n",
    "\"\"\"\n",
    "dataset.map() 裡面iter的東西會變成eagertensor 注意使用會有問題\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "注意astype 要使用 uint8  使用int8 會有問題\n",
    "urlopen  開啟 網址, read() 估計事byte 型式string, 使用BytesIO 開啟串流  然後就可以直接Image.open\n",
    "\"\"\"\n",
    "def load_image_into_numpy_array(path):\n",
    "    image = None\n",
    "    \n",
    "    if(path.startswith('http')):\n",
    "        response = urlopen(path)\n",
    "        image_data = response.read()\n",
    "        image_data = BytesIO(image_data)\n",
    "        image = Image.open(image_data)\n",
    "    else:\n",
    "        image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "    (im_width, im_height) = image.size\n",
    "    \"\"\"\n",
    "    這裡不錯  reshape 直接也處理了 batch size\n",
    "    \"\"\"\n",
    "    return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "這裡的圖片內部通道已經調整過  可以直接numpy()後 pltshow\n",
    "\"\"\"\n",
    "img = tf.io.read_file(path)\n",
    "img = tf.io.decode_jpeg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用PIL的resize 注意只能改w, h\n",
    "通到數可以在load img 時調整\n",
    "PIL轉np 正規畫  改dtype\n",
    "\"\"\"\n",
    "import glob\n",
    "from keras.preprocessing.image import img_to_array\n",
    "def process_img(list_data_path, label):\n",
    "    assert label == \"y\" or label == \"n\"\n",
    "    result = []\n",
    "#     data_paths = glob.glob(list_data_path+\"*\")\n",
    "    num = len(list_data_path)\n",
    "    for p in list_data_path:\n",
    "        pil = tf.keras.preprocessing.image.load_img(p)\n",
    "#         print(pil.size)\n",
    "#         print(pil.mode)\n",
    "        pil = pil.resize((224,224))\n",
    "        nparray = img_to_array(pil)\n",
    "#         nparray.reshape(224,224,3)\n",
    "        nparray = nparray.astype('float32')\n",
    "        nparray = nparray/255.0\n",
    "        print(nparray.shape)\n",
    "#         plt.imshow(nparray)\n",
    "        if label == \"y\":\n",
    "            result.append((nparray,1))\n",
    "        else:\n",
    "            result.append((nparray,0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "查看圖片資訊\n",
    "JPEG\n",
    "(300, 325)\n",
    "mode :L　=> L (8-bit pixels, black and white) 裡面最大值是255  最小值0 \n",
    "擊敗  所有圖片大小都不一樣\n",
    "幹 使用np .shape 變成(325, 300)\n",
    "注意  圖片竟是三通到\n",
    "\"\"\"\n",
    "from PIL import Image,ImageOps\n",
    "image = Image.open(\"/kaggle/input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset/yes/Y244.JPG\")\n",
    "\n",
    "print(image.format)\n",
    "print(image.size)\n",
    "print(image.mode)\n",
    "\n",
    "image\n",
    "\n",
    "array = np.array(image)\n",
    "\n",
    "array.max()\n",
    "\n",
    "array.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用tf.keras.preprocessing.image_dataset_from_directory\n",
    "\"\"\"\n",
    "對了 input shape 還必須要根據model選擇來調整\n",
    "先用個VGG16來測試\n",
    "注意  這種方式  資料夾必須要按照 \n",
    "main_directory/\n",
    "...class_a/\n",
    "......a_image_1.jpg\n",
    "......a_image_2.jpg\n",
    "...class_b/\n",
    "......b_image_1.jpg\n",
    "......b_image_2.jpg\n",
    "calling image_dataset_from_directory(main_directory, labels='inferred')\n",
    "就會按照 class_a, class_b label讀近來資料\n",
    "\n",
    "首先  資料夾結構不ok\n",
    "\"\"\"\n",
    "basereadPath = \"/kaggle/input/brain-mri-images-for-brain-tumor-detection/\"\n",
    "batchsize = 4\n",
    "img_height,img_width = Vgg16WH\n",
    "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(basereadPath, validation_split = 0.1, seed = 123,labels='inferred',\n",
    "                                                               image_size=(img_height, img_width),batch_size=batchsize ,subset=\"validation\")\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(basereadPath,  seed = 123,labels='inferred',\n",
    "                                                               image_size=(img_height, img_width),batch_size=batchsize )\n",
    "\n",
    "type(valid_ds)\n",
    "\n",
    "#現在valid_ds 確實有 13* 4 個資料  但是.... 我怎知其中有label 0, and 1 的資料  而且是那些??\n",
    "len(list(train_ds.as_numpy_iterator()))\n",
    "\n",
    "#到底標籤為何有2???\n",
    "\"\"\"\n",
    "幹  那是因為 底下還有個brain_tumor_dataset 資料夾\n",
    "\"\"\"\n",
    "for img, labels in valid_ds.take(1):\n",
    "#     print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_height, img_width = (224,224)\n",
    "batchsize = 4\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "#     rotation_range=40, # 角度值，0~180，影象旋轉\n",
    "    width_shift_range=0.1, # 水平平移，相對總寬度的比例\n",
    "    height_shift_range=0.1, # 垂直平移，相對總高度的比例\n",
    "    shear_range=0.2, # 隨機錯切換角度\n",
    "    zoom_range=0.2, # 隨機縮放範圍\n",
    "    brightness_range=[0.3, 1.5],\n",
    "    horizontal_flip=True, # 一半影象水平翻轉\n",
    "    fill_mode='nearest' # 填充新建立畫素的方法\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "先抓train 數量最多 可以直接使用 image_dataset_from_directory(裡面有label subset參樹)\n",
    "這裡改用ImageDataGenerator.flow_from_directory (沒有label, subset參樹 , 要改成 class_mode)\n",
    "\"\"\"\n",
    "train_base = \"/kaggle/input/brain-mri-images-for-brain-tumor-detection/brain_tumor_dataset/\"\n",
    "train_ds = data_gen.flow_from_directory(train_base,  seed = 123, class_mode='binary', color_mode = \"rgb\",\n",
    "                                                               target_size=(img_height, img_width), batch_size=batchsize ,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "這用來處理 test valid\n",
    "使用tf 毒入  所以資料就維tensor\n",
    "阿不是  資料讀近來 chanel 是 3 ??\n",
    "已經用tf.image.rgb_to_grayscale 修改 channel\n",
    "確認過灰階圖片沒問題\n",
    "\n",
    "注意:\n",
    "    下面code img 物件似乎不是一班的tensor  我猜可能是graph mode 下面的tensor\n",
    "    所以才會有reshape沒有維度的問題\n",
    "\"\"\"\n",
    "def map_images(file):\n",
    "#     img = tf.io.decode_image(tf.io.read_file(file))\n",
    "#     img = tf.dtypes.cast(img, tf.float32)\n",
    "#     img = img/255.0\n",
    "#     img = tf.image.rgb_to_grayscale(\n",
    "#     img, name=None\n",
    "#     )\n",
    "#     print(img.numpy())\n",
    "# #     img = tf.image.resize(img,size = [224,224])\n",
    "# #     img = tf.reshape(img, shape=(224, 224, 3,))\n",
    "# #     a = tf.reshape(img, [1,224,224,1])\n",
    "    tf.print(file)\n",
    "    tf.print(type(file))\n",
    "    img = tf.keras.preprocessing.image.load_img(file.numpy(), color_mode = \"grayscale\", target_size = (224,224), interpolation = \"nearest\")\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = np.array(img)\n",
    "    img = img/255.0\n",
    "    img = tf.convert_to_tensor(img, dtype=tf.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"CVC - Abnormal\": tf.io.FixedLenFeature( [],tf.int64), \n",
    "    \"CVC - Borderline\": tf.io.FixedLenFeature([],tf.int64),  \n",
    "    \"CVC - Normal\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"ETT - Abnormal\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"ETT - Borderline\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"ETT - Normal\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"NGT - Abnormal\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"NGT - Borderline\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"NGT - Incompletely Imaged\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"NGT - Normal\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"StudyInstanceUID\": tf.io.FixedLenFeature([],tf.string),\n",
    "    \"Swan Ganz Catheter Present\": tf.io.FixedLenFeature([],tf.int64),\n",
    "    \"image\": tf.io.FixedLenFeature([],tf.string),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "弄成numpy 的形式 x_train, y_train...\n",
    "tfrecords : tfdata set\n",
    "\n",
    "iter 轉換 example to dict, get meta data, label, image\n",
    "image rescale to 224*224*3, normolize, change dtype to float\n",
    "\n",
    "\"\"\"\n",
    "def make_Data_from_tfre(tfrecords):\n",
    "    X,Y = [],[]\n",
    "    meta = []\n",
    "    for raw_record in tfrecords:\n",
    "        example = tf.io.parse_single_example(raw_record, features)\n",
    "        values =[i.numpy() for i in list(example.values())[:-3]]\n",
    "    #     print(values)\n",
    "    \n",
    "        image = tf.io.decode_jpeg(example[\"image\"])\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        image = image.numpy()\n",
    "\n",
    "        meta.append((example[\"StudyInstanceUID\"], example[\"Swan Ganz Catheter Present\"]))\n",
    "        Y.append(values)\n",
    "        X.append(image)\n",
    "    return X,Y,meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_Y = pd.DataFrame(Y, columns=column_names)\n",
    "for col in pd_Y.columns:\n",
    "    pd_Y[col].hist()\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train,y_train)).shuffle(1024).batch(64)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid,y_valid)).batch(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
