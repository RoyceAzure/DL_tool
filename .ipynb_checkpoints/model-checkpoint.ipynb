{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "base_model = vgg16.VGG16(input_shape=(224,224,3), weights=\"imagenet\", include_top=False)\n",
    "\n",
    "\n",
    "# tf.keras.utils.plot_model(\n",
    "#     base_model, to_file='model.png', show_shapes=False, show_dtype=False,\n",
    "#     show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
    "# )\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "input_layer = base_model.input\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(4096, activation = \"relu\")(x)\n",
    "\n",
    "x = Dense(4096, activation = \"relu\")(x)\n",
    "\n",
    "output = Dense(2, activation = \"softmax\")(x)\n",
    "\n",
    "My_vgg16 = tf.keras.Model(input_layer, output)\n",
    "\n",
    "\n",
    "\n",
    "# My_vgg16.compile(loss = \"BinaryCrossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[F1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
    "        super(Block, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.repetitions = repetitions\n",
    "        \n",
    "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
    "        for i in range(self.repetitions):\n",
    "            \n",
    "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
    "            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(self.filters, self.kernel_size, activation = \"relu\", padding= \"same\")\n",
    "        \n",
    "        # Define the max pool layer that will be added after the Conv2D blocks\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D((pool_size,pool_size), strides)\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        # access the class's conv2D_0 layer\n",
    "        conv2D_0 = self.conv2D_0\n",
    "        \n",
    "        # Connect the conv2D_0 layer to inputs\n",
    "        x = inputs\n",
    "\n",
    "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
    "        for i in range(self.repetitions):\n",
    "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
    "            conv2D_i = vars(self)[f'conv2D_{i}']\n",
    "            # Use the conv2D_i and connect it to the previous layer\n",
    "            x = conv2D_i(x)\n",
    "\n",
    "        # Finally, add the max_pool layer\n",
    "        max_pool = self.max_pool(x)\n",
    "        \n",
    "        return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVGG(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyVGG, self).__init__()\n",
    "\n",
    "        # Creating blocks of VGG with the following \n",
    "        # (filters, kernel_size, repetitions) configurations\n",
    "        self.block_a = Block(64,3,2)\n",
    "        self.block_b = Block(128,3,2)\n",
    "        self.block_c = Block(256,3,3)\n",
    "        self.block_d = Block(512,3,3)\n",
    "        self.block_e = Block(512,3,3)\n",
    "\n",
    "        # Classification head\n",
    "        # Define a Flatten layer\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # Create a Dense layer with 256 units and ReLU as the activation function\n",
    "        self.fc = tf.keras.layers.Dense(units=256,activation=\"relu\")\n",
    "        # Finally add the softmax classifier using a Dense layer\n",
    "        self.classifier = tf.keras.layers.Dense(units=num_classes,activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Chain all the layers one after the other\n",
    "        x = self.block_a(inputs)\n",
    "        x = self.block_b(x)\n",
    "        x = self.block_c(x)\n",
    "        x = self.block_d(x)\n",
    "        x = self.block_e(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import urllib.request\n",
    "\n",
    "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "weights_file = \"inception_v3.h5\"\n",
    "urllib.request.urlretrieve(weights_url, weights_file)\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape=(224,224,3), include_top=False, weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "InceptionV3 最後一層 'mixed10'\n",
    "\"\"\"\n",
    "last_output = pre_trained_model.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Classifyer_Layer(pre_trained_model, last_output, class_num = None, mode = None):\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x = layers.Flatten()(last_output)\n",
    "    # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    # Add a final sigmoid layer for classification\n",
    "    \"\"\"\n",
    "    2分類??\n",
    "    \"\"\"\n",
    "    if mode == 0:\n",
    "        x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    else :\n",
    "        assert class_num is not None  and class_num >0, \"U must give class_num\"\n",
    "        x = layers.Dense(class_num, activation='softmax')(x)\n",
    "    model = Model(pre_trained_model.input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "計算一個 batchsize\n",
    "所以opt.apply_gradients 就已經更新model內部的權重了?\n",
    "\"\"\"\n",
    "def apply_gradient(model, x,y, opt, loss_obj):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        logits = model(x) #shape (b,1)\n",
    "#         print(\"y.shape: {}\".format(y.shape))\n",
    "#         print(\"y type: {}\".format(type(y)))\n",
    "#         print(\"logits: {}\".format(logits))\n",
    "        print(\"y: {}\".format(y))\n",
    "        loss = loss_obj(y, logits) #應該也是(b,1)\n",
    "#         print(\"loss: {}\".format(loss))\n",
    "    gradients = tape.gradient(loss, model.trainable_variables) # 這裡的維度應該跟model.trainable_weights 依樣\n",
    "#     print(\"gradients.shape: {}\".format(np.array(gradients).shape))\n",
    "#     print(\"gradients: {}\".format(gradients))\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))  #注意zip 重這裡來看  要馬 lossobj裡面有model資訊  要馬model.trainable_weights是shallow copy\n",
    "    \"\"\"\n",
    "    回傳model跑完結果 與loss\n",
    "    回傳logits 是因為要知道分類結果  用來給metric計算\n",
    "    \"\"\"\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "傳入model , opt, metric, 那要如何使用callback?? 像是tensorboard??  自己存 logits??\n",
    "因為需要做 actimap 所以不只要傳入dataset\n",
    "\"\"\"\n",
    "def train_one_epoch(model, dataset, optimizer, loss_obj, metrics, verbose, callback = None):\n",
    "    \"\"\"\n",
    "    每組data 都要記錄loss 最後在平均\n",
    "    也就是losses是要用來在epoch end 時使用\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(dataset):\n",
    "        logits, loss = apply_gradient(model, x_batch_train,y_batch_train, optimizer, loss_obj)\n",
    "        \"\"\"\n",
    "        每個batch 應計算callback, metric\n",
    "        \"\"\"\n",
    "        losses.append(loss)\n",
    "        \n",
    "        \"\"\"\n",
    "        預計使用多個metric\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        處理logits  確實不論是2分類  多分類  其logits 都是介於0~1  只是數量不同而已\n",
    "        可以的話  把每個為度印出來\n",
    "        只有到epoch end 時  才會把metric 資料show 出來\n",
    "        \"\"\"\n",
    "#         logits = tf.round(logits)\n",
    "#         logits = tf.cast(logits, 'int64')\n",
    "#         print(\"step :{}, before metric.update_state logits:{}\".format(step, logits))\n",
    "        \"\"\"\n",
    "                self.tp = tf.Variable(0, dtype = 'int32')\n",
    "        # false positives\n",
    "        self.fp = tf.Variable(0, dtype = 'int32')\n",
    "        # true negatives\n",
    "        self.tn = tf.Variable(0, dtype = 'int32')\n",
    "        # false negatives\n",
    "        self.fn = tf.Variable(0, dtype = 'int32')\n",
    "        \"\"\"\n",
    "        for metric in metrics:\n",
    "            metric.update_state(y_batch_train, logits)\n",
    "#             print(\"step :{}, after metric.update_state tp:{}, tn:{},fp:{}, fn:{}\".format(step, metric.tp, metric.tn, metric.fp, metric.fn))\n",
    "        \"\"\"\n",
    "        每個 batch 完應該要要出資訊\n",
    "        重這裡看來  似乎  資訊就是那些logits loss 你手動計算的結果就是全部資訊  內建obj並不會產稱而外資訊\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Training loss for step %s: %.4f\" % (int(step), float(loss)))\n",
    "    \"\"\"\n",
    "    losses 直接回傳  在外面再處理\n",
    "    \"\"\"\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "幹注意  這裡參樹應該都是shallow copy 吧?  應該不是deep copy 不然就不能這樣寫\n",
    "\"\"\"\n",
    "def valid_one_epoch(model, valid_dataset, loss_obj, val_metrics):\n",
    "    losses = []\n",
    "    \"\"\"\n",
    "    這裡x y batch size 應為1\n",
    "    \"\"\"\n",
    "    for step, (x, y) in enumerate(valid_dataset):\n",
    "        logits = model(x)\n",
    "        loss = loss_obj(y, logits)\n",
    "        losses.append(loss)\n",
    "#         logits = tf.cast(tf.round(logits), 'int64')\n",
    "#         print(\"in valid_one_epoch y.shape: {}  loss:{}  logits:{}\".format(y.shape, loss, logits))\n",
    "        for metric in val_metrics:\n",
    "            metric.update_state(y, logits)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epochs, model, train_dataset, valid_dataset, optimizer, loss_object, train_metrics, val_metrics):\n",
    "    epochs_val_losses, epochs_train_losses = [], []\n",
    "    for step in range(epochs):\n",
    "        \"\"\"\n",
    "        train one step\n",
    "            return bbatch size loss\n",
    "        \"\"\"\n",
    "        train_losses = train_one_epoch(model, train_dataset, optimizer, loss_object, train_metrics, 1)\n",
    "\n",
    "        \"\"\"\n",
    "        這裡要印出train_metrics結果\n",
    "        \"\"\"\n",
    "\n",
    "        mean_train_losses = np.mean(train_losses)\n",
    "        print(\"train section :\")\n",
    "        print(\"mean loss : {}\".format(mean_train_losses))\n",
    "        for metric in train_metrics:\n",
    "            metric.showCMs()\n",
    "            metric.result()\n",
    "            metric.reset_states()\n",
    "        \"\"\"\n",
    "        valid \n",
    "        \"\"\"\n",
    "        val_losses = valid_one_epoch(model, valid_dataset, loss_object, val_metrics)\n",
    "\n",
    "\n",
    "\n",
    "        mean_val_losses = np.mean(val_losses)\n",
    "        print(\"valid section :\")\n",
    "        pd_metric_result = []\n",
    "        print(\"mean loss : {}\".format(mean_val_losses))\n",
    "        for metric in val_metrics:\n",
    "            metric.showCMs()\n",
    "            metric.result()\n",
    "            metric.reset_states()\n",
    "\n",
    "        epochs_val_losses.append(mean_val_losses)\n",
    "        epochs_train_losses.append(mean_train_losses)\n",
    "    return epochs_train_losses, epochs_val_losses, pd_metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "需要包含 metric, actimap, visual option\n",
    "分類問題  希望可以有confuse metric\n",
    "等等  F1 acc recall ... 這些METRIC 都是2分類才有的??  也就是建立在tp tn fp fn 這四個指標上面\n",
    "\"\"\"\n",
    "def evaluateLoop(model, test_dataset, loss_object, test_metrics):\n",
    "    eval_losses = []\n",
    "    for step, (x,y) in enumerate(test_dataset):\n",
    "        logits = model.predict(x)\n",
    "        loss = loss_object(y, logits)\n",
    "        print(f\"eva step : {step}, loss : {loss}\")\n",
    "        eval_losses.append(loss)\n",
    "        for metric in test_metrics:\n",
    "            metric.update_state(y, logits)\n",
    "    for metric in test_metrics:\n",
    "        metric.result()\n",
    "    return eval_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_grad 只抓layer_name 這層來看?? 而且這是在近分類器前 的最後一層conv 結果 \n",
    "processed_image 又是指甚麼?\n",
    "\"\"\"\n",
    "def get_CAM(processed_image, actual_label, layer_name='block5_conv3'):\n",
    "    \"\"\"\n",
    "    model_grad 比起 myvgg16 就是多了layer_name這層output\n",
    "    \"\"\"\n",
    "    model_grad = Model([My_vgg16.input],[My_vgg16.get_layer(layer_name).output ,My_vgg16.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_output_values, predictions = model_grad(processed_image)\n",
    "        \"\"\"\n",
    "        現在才開始watch??\n",
    "        重點這邊conv_output_values 事很多層的結果\n",
    "        \"\"\"\n",
    "        tape.watch(conv_output_values)\n",
    "        #抓出predictions 第2個值  不知道地二個是貓還狗\n",
    "        pred_prob = predictions[:,1]\n",
    "        print(f\"pred_prob : {pred_prob}\")\n",
    "        # make sure actual_label is a float, like the rest of the loss calculation\n",
    "        actual_label = tf.cast(actual_label, dtype=tf.float32)\n",
    "        print(f\"actual_label : {actual_label}\")\n",
    "        smoothing = 0.00001\n",
    "        \"\"\"\n",
    "        為何要特地 使用binary cross來算loss 而且是特地抓predictions[:,1] 出來用這方法算loss, 為何不直接使用binary_cat_cros?\n",
    "        對阿 這裡目的只是要算最後loss 為何不使用lossobj??\n",
    "        \"\"\"\n",
    "        loss = -1 * (actual_label * tf.math.log(pred_prob + smoothing) + (1 - actual_label) * tf.math.log(1 - pred_prob + smoothing))\n",
    "        print(f\"binary loss: {loss}\")\n",
    "    \"\"\"\n",
    "    OH~ 所以是只要看 block5_conv3 這層 對最後loss的微分  合理\n",
    "    \n",
    "    \"\"\"\n",
    "    grads_values = tape.gradient(loss, conv_output_values) #shape 估計等同conv_output_values  沒錯 (1, 14, 14, 512)\n",
    "    print(\"before grads_values.shape: {}\".format(grads_values.shape))\n",
    "    \"\"\"\n",
    "    K.mean K.sum 這裡的指定axis 可以想成 指定到哪個維度  該維度經過合成運算就會變成1\n",
    "    \"\"\"\n",
    "    grads_values = K.mean(grads_values, axis=(0,1,2))#這裡是把batch, w, h 都做平均 也就是batch裡的不同圖片 的相同通道 平均成一個值 (512,)\n",
    "    print(\"after mean grads_values.shape: {}\".format(grads_values.shape))\n",
    "    print(\" conv_output_values.shape: {}\".format(conv_output_values.shape))\n",
    "    conv_output_values = np.squeeze(conv_output_values.numpy()) # 這裡有甚麼維度好縮檢的??\n",
    "    print(\"np.squeeze(conv_output_values.numpy().shape: {}\".format(np.squeeze(conv_output_values.shape)))\n",
    "    grads_values = grads_values.numpy() #看起來grads_values 的維度是(1,1,512) 就是所有通道自己平均\n",
    "    \"\"\"\n",
    "    然後每個conv_output_values 相對應的通道承上 該通道對於loss的平均\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(512): \n",
    "        conv_output_values[:,:,i] *= grads_values[i]\n",
    "        \n",
    "    \"\"\"\n",
    "    反正heat 就是縮減成w*h 然後每個pixel的質越大  代表其重要性越高\n",
    "    每個pixel 都是其他512個通道的平均 且每個通道都已經*上過梯度加權\n",
    "    注意  這裡heatmap 要還原成單一通道(數值大小)  所以512個通道要平均成 W*h\n",
    "    \"\"\"\n",
    "    heatmap = np.mean(conv_output_values, axis=-1)  #這邊又對通道做平均  我需要知道這裡維度便多少 (14, 14) 所以512個通道平均是??\n",
    "    print(f\"heatmap after np.mean: {heatmap.shape}\")\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    print(f\"np.maximum(heatmap, 0): {heatmap}\")\n",
    "    heatmap /= heatmap.max()\n",
    "    print(f\"heatmap.max(): {heatmap}\")\n",
    "    del model_grad, conv_output_values, grads_values, loss\n",
    "   \n",
    "    return heatmap\n",
    "\"\"\"\n",
    "binary loss: [ 1.1189777e+01 -6.1988640e-06]\n",
    "before grads_values.shape: (1, 14, 14, 512)\n",
    "after mean grads_values.shape: (512,)\n",
    " conv_output_values.shape: (1, 14, 14, 512)\n",
    "np.squeeze(conv_output_values.numpy().shape: [ 14  14 512]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "也就是 dataset 是可以用index 選資料???\n",
    "注意 sample_label 是(2,) softamx 刑事\n",
    "why 每個avti 都是 4 為?  我以就是一張圖片\n",
    "因為是 keras model, \\所以input, output都是有 batch size 這個維度\n",
    "也就是就算一張圖片  其 output也有\n",
    "My_vgg16.predict() # shape = (1,2) 難怪np.argmax 要用 axis=-1\n",
    "\n",
    "\n",
    "activations: 就是 vis_model predict 結果  也就是你指定的conv 層 output\n",
    "\n",
    "\"\"\"\n",
    "def show_sample(idx=None):\n",
    "    # if image index is specified, get that image\n",
    "    if idx:\n",
    "        for img, label in test_dataset.take(idx):\n",
    "            sample_image = img[0]\n",
    "            sample_label = label[0]\n",
    "    # otherwise if idx is not specified, get a random image\n",
    "    else:\n",
    "        for img, label in test_dataset.shuffle(1000).take(1):\n",
    "            sample_image = img[0]\n",
    "            sample_label = label[0]\n",
    "    sample_image_processed = np.expand_dims(sample_image, axis=0)\n",
    "    activations = vis_model.predict(sample_image_processed) #多個 (1,w,h,c) 就是cnn出來的結果\n",
    "    pred_label = np.argmax(My_vgg16.predict(sample_image_processed), axis=-1)[0]#np.argmax(My_vgg16.predict(sample_image_processed), axis=-1)  shape = (1,)\n",
    "    \n",
    "    \"\"\"\n",
    "    sample_activation 就是隨機抓某一層的某一個channel 來做顯示\n",
    "    我們可以看到這裡沒有做resize 因為她的wh 跟 input 依樣\n",
    "    \"\"\"\n",
    "    sample_activation = activations[0][0,:,:,16] #抓地0個?  阿布就Input?? 那16個通道是怎樣??? 等等 地0個怎會有64個通道 其實不同channel 就是代表不同filter過濾結果\n",
    "    sample_activation = activations[0][0,:,:,16]\n",
    "    sample_activation-=sample_activation.mean()\n",
    "    sample_activation/=sample_activation.std()\n",
    "    sample_activation *=255\n",
    "    sample_activation = np.clip(sample_activation, 0, 255).astype(np.uint8) #WTF 那圖片出來我的天\n",
    "    \"\"\"\n",
    "    這事在還原???  完全跟input\n",
    "    \"\"\"\n",
    "\n",
    "    heatmap = get_CAM(sample_image_processed, sample_label)\n",
    "    \"\"\"\n",
    "    接下來是heatmap 還原過程\n",
    "    這裡我就不懂了  這裡 conv heatmap 的結果就是14*14  這裡你要用resize 調到原本的224*224?? 或許也可以拉  反正只是要看哪部分重要\n",
    "\n",
    "     \"\"\"\n",
    "    heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n",
    "    heatmap = heatmap *255\n",
    "    heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n",
    "    \"\"\"\n",
    "    applyColorMap 就是一種將強度轉乘顏色的東西  有很多行是的顏色可以轉\n",
    "    cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) → dst.\n",
    "    就是圖片疊加\n",
    "    \"\"\"\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT)\n",
    "    converted_img = sample_image.numpy()\n",
    "    super_imposed_image = cv2.addWeighted(converted_img, 0.8, heatmap.astype('float32'), 2e-3, 0.0)\n",
    "    \n",
    "    \n",
    "    f,ax = plt.subplots(2,2, figsize=(15,8))\n",
    "\n",
    "    ax[0,0].imshow(sample_image)\n",
    "    ax[0,0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label}\")\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    ax[0,1].imshow(sample_activation)\n",
    "    ax[0,1].set_title(\"Random feature map\")\n",
    "    ax[0,1].axis('off')\n",
    "\n",
    "    ax[1,0].imshow(heatmap)\n",
    "    ax[1,0].set_title(\"Class Activation Map\")\n",
    "    ax[1,0].axis('off')\n",
    "\n",
    "    ax[1,1].imshow(super_imposed_image)\n",
    "    ax[1,1].set_title(\"Activation map combined with ori input\")\n",
    "    ax[1,1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "activations 就是 vis model [1:]的layer , 也就是layer_names 這兩者是對應的\n",
    "activations : list of keraTensor(layer.output)\n",
    "\"\"\"\n",
    "\n",
    "def visualize_intermediate_activations(layer_names, activations):\n",
    "    assert len(layer_names)==len(activations), \"Make sure layers and activation values match\"\n",
    "    images_per_row=16\n",
    "    \n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        \"\"\"\n",
    "        果然  他是把所有通道的圖都秀出來\n",
    "        這裡有個重點  就是不同層的acti  其裡面w h c 都不一樣\n",
    "        \"\"\"\n",
    "        nb_features = layer_activation.shape[-1]# 把該層 有多少個channel 抓出來\n",
    "        size= layer_activation.shape[1] #layer output 應該會有b 這個維度 所以 shape[1] 估計是 w 但是因為圖片w h 都相等  所以只須抓一個數值\n",
    "\n",
    "        nb_cols = nb_features // images_per_row\n",
    "        grid = np.zeros((size*nb_cols, size*images_per_row)) #這裡的grid 已經是pixel 等級的了 (h, w)\n",
    "\n",
    "        for col in range(nb_cols): #每個h\n",
    "            for row in range(images_per_row): #每個w\n",
    "                feature_map = layer_activation[0,:,:,col*images_per_row + row]\n",
    "                \n",
    "                \"\"\"\n",
    "                看來這是通用的 conv map 處理過程:\n",
    "                    feature_map -= feature_map.mean()\n",
    "                    feature_map /= feature_map.std()\n",
    "                    feature_map *=255\n",
    "                    feature_map = np.clip(feature_map, 0, 255).astype(np.uint8)\n",
    "                \"\"\"\n",
    "                feature_map -= feature_map.mean()\n",
    "                feature_map /= feature_map.std()\n",
    "                feature_map *=255\n",
    "                feature_map = np.clip(feature_map, 0, 255).astype(np.uint8)\n",
    "\n",
    "                grid[col*size:(col+1)*size, row*size:(row+1)*size] = feature_map #每個圖片h : col*size:(col+1)*size, w:row*size:(row+1)*size\n",
    "        \"\"\"\n",
    "        已經把每個avti 所有channel 像素等級的grid 製作完成\n",
    "        所以這裡是再說 plt.imshow 可以使用for 印出所有的 map\n",
    "        \"\"\"\n",
    "        scale = 1./size\n",
    "        print(f\"size : {size}, scale : {scale}\")\n",
    "        plt.figure(figsize=(scale*grid.shape[1], scale*grid.shape[0]))\n",
    "        print(f\"grid.shape[1] : {grid.shape[1]}, grid.shape[0] : {grid.shape[0]}\")\n",
    "        print(f\"scale w : {scale*grid.shape[1]}, scale h : {scale*grid.shape[0]}\")\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(grid, aspect='auto', cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run this!!\n",
    "\"\"\"\n",
    "urlopen  開啟 網址, read() 估計事byte 型式string, 使用BytesIO 開啟串流  然後就可以直接Image.open\n",
    "\"\"\"\n",
    "def load_image_into_numpy_array(path):\n",
    "    image = None\n",
    "    \n",
    "    if(path.startswith('http')):\n",
    "        response = urlopen(path)\n",
    "        image_data = response.read()\n",
    "        image_data = BytesIO(image_data)\n",
    "        image = Image.open(image_data)\n",
    "    else:\n",
    "        image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "    (im_width, im_height) = image.size\n",
    "    \"\"\"\n",
    "    這裡不錯  reshape 直接也處理了 batch size\n",
    "    \"\"\"\n",
    "    return np.array(image.getdata()).reshape(\n",
    "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "ALL_MODELS = {\n",
    "'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n",
    "'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n",
    "'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n",
    "'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n",
    "'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n",
    "'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n",
    "'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n",
    "'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n",
    "'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n",
    "'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n",
    "'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n",
    "'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n",
    "'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n",
    "'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n",
    "'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n",
    "'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n",
    "'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
    "'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n",
    "'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n",
    "'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n",
    "'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n",
    "'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n",
    "'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n",
    "'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n",
    "'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n",
    "'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n",
    "'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n",
    "'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n",
    "'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n",
    "'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n",
    "'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n",
    "'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n",
    "'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n",
    "'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n",
    "'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n",
    "'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n",
    "'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n",
    "'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
    "'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "所以可以直接這樣 抓圖片???\n",
    "\"\"\"\n",
    "\n",
    "IMAGES_FOR_TEST = {\n",
    "  'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n",
    "  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',\n",
    "  # By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg\n",
    "  'Naxos Taverna' : 'https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg',\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n",
    "  'Beatles' : 'https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg',\n",
    "  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n",
    "  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n",
    "  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\n",
    "  'Birds' : 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg',\n",
    "}\n",
    "\n",
    "COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n",
    " (0, 2),\n",
    " (1, 3),\n",
    " (2, 4),\n",
    " (0, 5),\n",
    " (0, 6),\n",
    " (5, 7),\n",
    " (7, 9),\n",
    " (6, 8),\n",
    " (8, 10),\n",
    " (5, 6),\n",
    " (5, 11),\n",
    " (6, 12),\n",
    " (11, 12),\n",
    " (11, 13),\n",
    " (13, 15),\n",
    " (12, 14),\n",
    " (14, 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "看來 api 裡面已經有存一些資料的 label map\n",
    " 適用 id : {\n",
    "     id: \n",
    "     name:\n",
    " }\n",
    " 使用abel_map_util.create_category_index_from_labelmap  可直接讀近來轉成 dict\n",
    "\"\"\"\n",
    "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "handel 已經用 list 處理好\n",
    "\"\"\"\n",
    "model_display_name = 'CenterNet HourGlass104 Keypoints 512x512' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']\n",
    "model_handle = ALL_MODELS[model_display_name]\n",
    "\n",
    "\"\"\"\n",
    "直接load (網址就可以)  她媽的方便\n",
    "\"\"\"\n",
    "print('loading model...')\n",
    "hub_model = hub.load(model_handle)\n",
    "print('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Image Selection (don't forget to execute the cell!) { display-mode: \"form\"}\n",
    "selected_image = 'Beach' # @param ['Beach', 'Dogs', 'Naxos Taverna', 'Beatles', 'Phones', 'Birds']\n",
    "flip_image_horizontally = False #@param {type:\"boolean\"}\n",
    "convert_image_to_grayscale = False #@param {type:\"boolean\"}\n",
    "\n",
    "image_path = IMAGES_FOR_TEST[selected_image]\n",
    "\"\"\"\n",
    "load_image_into_numpy_array 是給網址抓圖片  只抓一張  轉成np 並處理維度\n",
    "算是好用\n",
    "\"\"\"\n",
    "image_np = load_image_into_numpy_array(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip horizontally\n",
    "if(flip_image_horizontally):\n",
    "    image_np[0] = np.fliplr(image_np[0]).copy()\n",
    "\n",
    "# Convert image to grayscale\n",
    "\"\"\"\n",
    "注意這裡轉灰階的方式\n",
    "numpy.fliplr(m)[source]\n",
    "    Flip array in the left/right direction.\n",
    "\n",
    "    Flip the entries in each row in the left/right direction. Columns are preserved, but appear in a different order than before.\n",
    "    \n",
    "numpy.tile(A, reps)[source]\n",
    "    Construct an array by repeating A the number of times given by reps.\n",
    "\"\"\"\n",
    "if(convert_image_to_grayscale):\n",
    "    image_np[0] = np.tile(\n",
    "    np.mean(image_np[0], 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(24,32))\n",
    "plt.imshow(image_np[0])\n",
    "plt.show()\n",
    "\n",
    "# running inference\n",
    "results = hub_model(image_np)\n",
    "\n",
    "# different object detection models have additional results\n",
    "# all of them are explained in the documentation\n",
    "result = {key:value.numpy() for key,value in results.items()}\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'mish'\n",
    "\n",
    "\n",
    "def mysoftplus(x):\n",
    "\n",
    "    mask_min = tf.cast((x<-20.0),tf.float32)\n",
    "    ymin = mask_min*tf.math.exp(x)\n",
    "\n",
    "    mask_max = tf.cast((x>20.0),tf.float32)\n",
    "    ymax = mask_max*x\n",
    "    \n",
    "    mask= tf.cast((abs(x)<=20.0),tf.float32)\n",
    "    y = mask*tf.math.log(tf.math.exp(x) + 1.0)\n",
    "    \n",
    "    return(ymin+ymax+y)    \n",
    "        \n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return (x* tf.math.tanh(mysoftplus(x)))\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "get_custom_objects().update({'mish': Mish(mish)})\n",
    "\n",
    "def _conv_block(inp, convs, skip=False):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    \n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)), name='zerop_' + str(conv['layer_idx']))(x)  # peculiar padding as darknet prefer left and top\n",
    "        \n",
    "        x = Conv2D(conv['filter'], \n",
    "                   conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='convn_' + str(conv['layer_idx']) if conv['bnorm'] else 'conv_' + str(conv['layer_idx']),\n",
    "                   use_bias=True)(x)\n",
    "        \n",
    "        if conv['bnorm']: x = BatchNormalization(name='BN_' + str(conv['layer_idx']))(x)    \n",
    "        \n",
    "        if conv['activ'] == 1: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "        if conv['activ'] == 2: x = Activation('mish', name='mish_' + str(conv['layer_idx']))(x) \n",
    "            \n",
    "    return add([skip_connection, x],  name='add_' + str(conv['layer_idx']+1)) if skip else x\n",
    "\n",
    "def make_yolov4_model():\n",
    "  \n",
    "    input_image = Input(shape=(NETWORK_H, NETWORK_W, 3), name='input_0')\n",
    "\n",
    "    # Layer  0\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 0}])\n",
    "    layer_0 = x\n",
    "    # Layer  1\n",
    "    x = _conv_block(x, [{'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 1}])\n",
    "    layer_1 = x\n",
    "    \n",
    "    # Layer  2 \n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 2}])\n",
    "    layer_2 = x\n",
    "    \n",
    "    # route  1 (layers = -2)\n",
    "    x = layer_1\n",
    "    # Layer  3 => 5\n",
    "    x = _conv_block(x, [{'filter': 64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 4},\n",
    "                        {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 5},\n",
    "                        {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 6}],\n",
    "                   skip = True)\n",
    "\n",
    "    # Layer  8 => 8\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 8}])\n",
    "    layer_8 = x\n",
    "    \n",
    "    # route  8+2 (layers = -1, -7)\n",
    "    x = concatenate([layer_8, layer_2], name='concat_9')\n",
    "    \n",
    "    # Layer 10 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 10},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 11}])\n",
    "    layer_11 = x\n",
    "    \n",
    "    # Layer  12\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 12}])\n",
    "    layer_12 = x\n",
    "    \n",
    "    # route  11 (layers = -2)\n",
    "    x = layer_11\n",
    "    # Layer 14 => 16\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 14},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 15},\n",
    "                        {'filter':  64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 16}],\n",
    "                   skip = True)\n",
    "    \n",
    "    # Layer 18 => 19\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 18},\n",
    "                        {'filter':  64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 19}],\n",
    "                   skip = True)\n",
    "    \n",
    "    # Layer  21\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 21}]) \n",
    "    layer_21 = x\n",
    "    \n",
    "    # route  21+12 (layers = -1,-10)\n",
    "    x = concatenate([layer_21, layer_12], name='concat_22')\n",
    "    \n",
    "    # Layer 23 => 24\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 23},\n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 24}])\n",
    "    layer_24 = x\n",
    "    \n",
    "    # Layer  25\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 25}])\n",
    "    layer_25 = x\n",
    "    \n",
    "    # route  24 (layers = -2)\n",
    "    x = layer_24\n",
    "    \n",
    "    # Layer 27 => 29\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 27},\n",
    "                        {'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 28},\n",
    "                        {'filter':  128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 29}],\n",
    "                   skip = True)\n",
    "    \n",
    "    # Layer 31 => 50\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 31+(i*3)},\n",
    "                            {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 32+(i*3)}],\n",
    "                       skip = True)\n",
    "  \n",
    "    # Layer  52\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 52}])\n",
    "    layer_52 = x\n",
    "        \n",
    "    # route  52+25 (layers = -1,-28)\n",
    "    x = concatenate([layer_52, layer_25],  name='concat_53')\n",
    "    \n",
    "    # Layer 54\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 54}])\n",
    "    layer_54 = x\n",
    "    \n",
    "    # Layer  55\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 55}])\n",
    "    layer_55 = x\n",
    "    \n",
    "    # Layer  56\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 56}])\n",
    "    layer_56 = x\n",
    "    \n",
    "    # route  55 (layers = -2)\n",
    "    x = layer_55\n",
    "    \n",
    "    # Layer 58 => 60\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 58},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 59},\n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 60}],\n",
    "                   skip = True)     \n",
    "\n",
    "    # Layer 62 => 81\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 62+(i*3)},\n",
    "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 63+(i*3)}],\n",
    "                       skip = True)\n",
    "\n",
    "    # Layer  83\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 83}])\n",
    "    layer_83 = x\n",
    "\n",
    "    # route  83+56 (layers = -1,-28)\n",
    "    x = concatenate([layer_83, layer_56], name='concat_84')\n",
    "    \n",
    "    # Layer 85\n",
    "    x = _conv_block(x, [{'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 85}])\n",
    "    layer_85 = x\n",
    "    \n",
    "    # Layer  86\n",
    "    x = _conv_block(x, [{'filter':  1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 86}])\n",
    "    layer_86 = x\n",
    "    \n",
    "    # Layer  87\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 87}])\n",
    "    layer_87 = x\n",
    "        \n",
    "    # route  86 (layers = -2)\n",
    "    x = layer_86\n",
    "    \n",
    "    # Layer 89 => 92\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 89},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 90},\n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 91}],\n",
    "                   skip = True) \n",
    "    \n",
    "    \n",
    "    # Layer 93 => 100\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 93+(i*3)},\n",
    "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 94+(i*3)}],\n",
    "                       skip = True)  \n",
    "    \n",
    "    \n",
    "    # Layer  102 => 102\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 102}])  \n",
    "    layer_102 = x\n",
    "    \n",
    "    # route  102+87 (layers = -1,-16)\n",
    "    x = concatenate([layer_102, layer_87], name='concat_103')\n",
    "    \n",
    "    # Layer 104 => 107\n",
    "    x = _conv_block(x, [{'filter':  1024, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 104},\n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 105},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 106},                        \n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 107}])\n",
    "    layer_107 = x\n",
    "    \n",
    "    # Layer 108\n",
    "    x =MaxPool2D(pool_size=(5, 5), strides=1, padding='same', name = 'layer_108')(x)  \n",
    "    layer_108 = x\n",
    "    \n",
    "    # route  107 (layers = -2)\n",
    "    x = layer_107\n",
    "    \n",
    "    # Layer 110\n",
    "    x =MaxPool2D(pool_size=(9, 9), strides=1, padding='same', name = 'layer_110')(x)    \n",
    "    layer_110 = x\n",
    "    \n",
    "    # route  107 (layers = -4)\n",
    "    x = layer_107\n",
    "        \n",
    "    # Layer 112\n",
    "    x =MaxPool2D(pool_size=(13, 13), strides=1, padding='same', name = 'layer_112')(x) \n",
    "    layer_112 = x\n",
    "    \n",
    "    # route  112+110+108+107 (layers=-1,-3,-5,-6)\n",
    "    x = concatenate([layer_112, layer_110, layer_108, layer_107], name='concat_113')\n",
    "    layer_113 = x\n",
    "    \n",
    "    # Layer 114 => 116\n",
    "    x = _conv_block(x, [{'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 114},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 115},\n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 116}])\n",
    "    layer_116 = x\n",
    "                        \n",
    "    # Layer 117                    \n",
    "    x = _conv_block(x, [{'filter':   256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 117}])\n",
    "    layer_117 = x\n",
    "    # Layer 118\n",
    "    x = UpSampling2D(size=(2, 2), name = 'upsamp_118')(x)\n",
    "    layer_118 = x\n",
    "                        \n",
    "    # route  85 (layers = 85)\n",
    "    x = layer_85\n",
    "    \n",
    "    # Layer 120\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 120}])\n",
    "    layer_120 = x\n",
    "                        \n",
    "    # route  120+118 (layers = -1, -3)\n",
    "    x = concatenate([layer_120, layer_118],  name='concat_121')\n",
    "    layer_121 = x                    \n",
    "    # Layer 122 => 126\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 122},\n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 123},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 124},  \n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 125},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 126}])\n",
    "    layer_126 = x \n",
    "                        \n",
    "    # Layer 127                    \n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 127}])\n",
    "    layer_127 = x\n",
    "    # Layer 128\n",
    "    x = UpSampling2D(size=(2, 2), name = 'upsamp_128')(x)\n",
    "    layer_128 = x\n",
    "                        \n",
    "    # route  54 (layers = 54)\n",
    "    x = layer_54\n",
    "    \n",
    "    # Layer 130\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 130}])\n",
    "    layer_130 = x\n",
    "                        \n",
    "    # route  130+128 (layers = -1, -3)                 \n",
    "    x = concatenate([layer_130, layer_128],  name='concat_131')\n",
    "    layer_131 = x                    \n",
    "    # Layer 132 => 136\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 132},\n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 133},\n",
    "                        {'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 134},  \n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 135},\n",
    "                        {'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 136}])\n",
    "    layer_136 = x                   \n",
    "    \n",
    "    # Layer 137 => 138\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 137}]) \n",
    "    layer_137 = x \n",
    "    x = _conv_block(x, [{'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  0, 'layer_idx': 138}])   \n",
    "  \n",
    "    # Layer 139\n",
    "    yolo_139 = x\n",
    "                        \n",
    "    # route  136 (layers = -4)\n",
    "    x = layer_136\n",
    "    \n",
    "    # Layer 141\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 1, 'layer_idx': 141}])\n",
    "    layer_141 = x\n",
    "                        \n",
    "    # route  141+126 (layers = -1, -16)                   \n",
    "    x = concatenate([layer_141, layer_126],  name='concat_142')\n",
    "    \n",
    "    # Layer 143 => 147\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 143},\n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 144},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 145},  \n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 146},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 147}])  \n",
    "    layer_147 = x\n",
    "                        \n",
    "    # Layer 148 => 149                    \n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 148},\n",
    "                        {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  0, 'layer_idx': 149}])\n",
    "                        \n",
    "    # Layer 150\n",
    "    yolo_150 = x                  \n",
    "    \n",
    "    # route  147 (layers = -4)\n",
    "    x = layer_147\n",
    "        \n",
    "    # Layer 152\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 1, 'layer_idx': 152}])\n",
    "    layer_152 = x  \n",
    "                        \n",
    "    # route  152+166 (layers = -1, -37)                   \n",
    "    x = concatenate([layer_152, layer_116],  name='concat_153') \n",
    "                        \n",
    "                        \n",
    "    # Layer 154 => 160\n",
    "    x = _conv_block(x, [{'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 154},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 155},\n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 156},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 157},  \n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 158},   \n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 159},\n",
    "                        {'filter':   255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    0, 'layer_idx': 160}])  \n",
    "                     \n",
    "                        \n",
    "    # Layer 161\n",
    "    yolo_161 = x\n",
    "                           \n",
    "    model = Model(input_image, [yolo_139, yolo_150, yolo_161], name = 'Yolo_v4')    \n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
